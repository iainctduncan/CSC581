Overview
=========

ScmSeq is a Scheme-based sequencing platform. 
It is designed to be an equivalent of Emacs for sequencers - all sequencing activity is implemented
in Scheme, and runs in Max or M4L in one or more Scheme for Max externals.
This document provides a high-level overview of what it is, what motivated it,
its feature goals, and how the implementation meets these goals.

Design Objectives and Features
------------------------------
The high-level objective of ScmSeq was to create a real-time, multi-user step sequencing
environment that is fast enough to be usable in an improvised context, but that is also
a highly flexible algorithmic composition and live coding platform, and that makes no assumptions
about how music works and can thus be used for popular or contemporary concert music alike. 

To this end, some of the design goals were:

* Everything the platform does should be sequenceable - there should be no restrictions on what
  may be included in a score, triggered from live input, or driven from an algorithm.

* Input control should be decoupled from the GUI, and designed in a way that allows modal
  editing such as is common with Vim or Emacs. It should be possible to create input modes
  that, given sufficient practice on the part of the user, are very fast for data entry, 
  and crucially, require no visual confirmation cues. The principle here being that
  if you need to look at the screen to do an action, the workflow is not fast enough.

* It should be straighforward for the user to develop complex input modes ("Controllers"),
  taking advantage of whatever MIDI hardware they have available. Crucially, the modal
  approach means that the same physical controller may do very different things depending
  on the user's current mode, and thus the code should make creating and navigating these
  complex branching trees practical. It should allow more than one controller to be active at 
  a time, and should allow the user to specify which editing selections are stored as local
  to a particular input mode and which are global across input modes.

* Visual output should be decoupled from input so that multiple users (or automated processes) 
  can provide input 
  at the same time in a client-server fashion, regardless of what is showing on screen.
  This will also allow any visual displays to be accurate even if algorithmic processes are changing
  the sequencing data. It should be possible for visual output to display on multiple devices
  (including MIDI hardware) and it should be possible to tune the performance of these so
  that visual output does not become a performance bottleneck. 

* Each sequencer track should be clockable on its own, capable of different tempi, time
  signatures, or even notions of time. Step sequencers have many interesting advantages
  over regular midi sequencers, but few (if any) commercial step sequencers are designed
  to support non-standard or shifting meters, or variable meters between tracks.
  Additionally, locking in with the master transport in Ableton Live should be tight enough that one
  can combine material from the sequencers with material in regular Live tracks. 

* The platform should play well with commercial software, rather than forcing the user
  to use an all-or-nothing approach such as one gets with projects like Common Music.
  By implementing this in Max, it is possible for ScmSeq to run inside Ableton Live, or
  in standalone Max in conjunction with other environments (DAWs, Csound, etc.)
 
* All components should be possible to edit or redefine on the fly using a Lisp REPL.
  It should be possible to work on the software while the music is playing.
  In essence, one should be able to live-code any of the implementation.


The current version is the 4th iteration of this project, the first having been created
in 2004 in Csound, followed by an incomplete C++ version, and a Max/JavaScript version in 
about 2018 as part of the UVic Music 507 course with Dr. Andy Schloss.
In fact, Scheme for Max itself came out of the desire to make a better version of the  
project, requiring better tools for creating it, and was developed as part of directed
studies with Dr. Schloss as a continuation of the Mus 507 material.

The remainder of this document will discuss the implementation of the platform
at a high level and how it achieves these objectives.

Event Sequencing 
----------------
ScmSeq is fundamentally an **event step-sequencing system**, where an event can
be anything one might execute in the Scheme environment or the Max environment.
This is accomplished by having all activity triggered by Scheme function calls.
(Which, in fact, is how Emacs works as well, where all editor actions
are actually Elips calls.)
Scheme function calls may in turn trigger Max events by sending messages to Max objects through the S4M
message sending capability or through regular patching.

At the lower level of the indiviual step sequencer components, 
ScmSeq considers an event to be the output of an arbitrarily long list of numbers (and maybe symbols).
This is then handled by a function that does whatever the user wants with them, and
as it is trivial to redefine or add new functions (even while playing), the user can easily create
output functions that play midi notes, control CV output, trigger Live API events,
or call other arbitrary Scheme functions (including those scheduled for the future).

The standard implementation of the step sequencer component outputs event messages
that are similar to a Music-N or Csound score event: 
the first field specifies the destination of the event,
the second specifies duration, and the rest can be arbitrarily intrepreted
by the destination handler. (Similar to Csound p1 and p3, with a p2 assumes to be 0.)
This differs in significant ways from a MIDI-centric system, in that in a MIDI system, an event's duration 
is not known from its triggering message, but is instead unknown until a subsequent note-off message.
Thus, unlike in a MIDI sequencer, ScmSeq considers an event to be merely the timed output 
of a set of parameters to some handler function. (Though in fact, there is nothing in ScmSeq forcing
the output list to be used in any particular way, one could decide to use durationless messages,
or even implement a note-off style instrument.)

An advantage of handling events in this score-like fashion is that output handlers (most commonly components that play a note)
can know their end time from the beginning of the event, allowing them to shape processes 
and envelopes accordingly. 
Additionally, event parameters are not limited to the number of fields in a MIDI message, 
and the user does not have to use MIDI cc messages to send channel-global messages to change 
other parameters. This is, in some ways, similar to MIDI polyphonic expression (one sends
parameters to specific notes), but is more open ended.
This enables techniques that are particularly cumbersome in MIDI-centric implementations,
such as notes that recursively trigger altered versions of themselves, or instruments
that glide to the pitch of the next *before* the attack onset of the next note.

The nature of Scheme means that it is also trivial to make a handler that translates
from a list of parameters to a function call, allowing one to make sequencers that sequence
sequencers, to any depth of recursion.

Modal Input & MVC Design
--------------------------------------------------------
To achieve the design goals of modal input and decoupled input and visual output, 
ScmSeq uses a true Model-View-Controller pattern, as this term was used originally
in the context of Smalltalk desktop systems. 
What is meant by this is that:

* The sequencer engine that plays events (the model) does not depend in any way on components
  used for display (the view), or those used for input (the controllers).
* Views likewise do not depend on controllers; they are driven by functions that 
  are run on periodic timers and which query the sequencers for current
  sequencing data, sending messages to display components accordingly. 
  Views can be Max GUI widgets, but also any external display that can be triggered from
  a Max message, including hardware controllers that allow LED updating or anything
  we might send messages to over the network.
* Controllers listen for input from the user (most commonly from MIDI devices), 
  and send messages to sequencer components requesting data updates. 
  Controllers have state of their own, and may also read global state,
  allowing them to be modal in the sense of Vim or Emacs modes. 
  Controllers may also directly update some output GUI 
  widgets intended to display Controller state. 

Additionally:

* All components are implemented as Scheme objects that receive symbolic messages
  and that can update internal or global state and send messages in turn.
  These are instantiated as functions-as-objects, where sending a message
  consists of a call with the first symbol argument used to indicate the method.
* Components share a number of standard interfaces, thus the user can easily
  make utilities that rely on common messages across components, and can
  send these messages from a REPL in a live-coding manner.

This design does have some performance consequences, in that this GUI is in effect
an *immediate mode GUI*, where screens always update off data state and thus
there are constantly queries to the state repostitories. 
However, these are manageable by tuning the frequency of queries, 
and the design has a number of significant advantages:

* The engine and views have no dependency on the number or type of input streams
  running to controllers. This makes multi-user, multi-device, and multi-mode input easy to configure. In a sense
  controllers are clients of an engine server and adding more of them is simple.
* Views can be adjusted to update as frequently as desired for performance. In
  a music context, I have found a very low frequency is acceptable provided the
  input modes are designed such that one does not need *visual confirmation*. If
  the views are showing the state of the data only, an update every 16th note is ample.
* Views always reflect the current sequencer data - regardless of where this is 
  coming from. This means that sequences may be altered by multiple users,
  by algorithmic agents, or by events coming in over the local network, and
  views will still always show the correct data. This also allows
  views to run on other machines or in other processes.
* As each controller module is self-contained with its own state, controllers 
  can themselves be sequenced. For example, a controller that mutes and
  unmutes tracks based on the incoming MIDI notes can be controlled from 
  a ScmSeq sequencer or a built in track sequencer in Live, or even an
  external process capable of sending midi notes. I have used this succesfully
  to drive arrangement-level events from Ableton Live scene-triggered clips, for example.
  

Sequencer Clocking
------------------
A fundamental goal of this system was to make it possible to step-sequence
contemporary concert music. The heurisic I use is: *Could I program in
Edgar Varese's 'Ionization'?*, a complex piece in which there are shifting meters and different
instruments playing in different meters at the same time.

To achieve this, each track runs in its own sequencer object, where this object
is itself responsible for its clocking. In some of the literature this is called
"temporal recursion", meaning a function call is reponsible for scheduling the next
execution of itself. Scheme for Max provides a variety of scheduling functions,
some of which are synchronized with the global transport and others not. 
This allows ScmSeq to be used in the context of Ableton Live, with Scheme sequencing
aligned with regular Live sequencing, but also allows sequencers to do some interesting
things:

* They (or the user) can change their timebase as they play, enabling
  processes that change tempo, meter, or use shifting meters.
* The notion of a step does not necessarily have to imply that a step is always
  of the same duration. Durations can follow patterns, be randomized, or be sequenced 
  from other tools.
* Sequencers can run hook functions on certain life-cycle events and alter
  their clocking as they go. I explored this technique in a stochastic piece
  in which note and phrase boundaries introduced various degrees of randomization 
  to step lengths.

The combination of the ability to clock off the Live transport or off a totally
independent clock means that it is possible to program something like Ionization
within the Live environment.

REPL and Live-Coding
--------------------
Finally, ScmSeq succeeds in offering an environment that is highly flexible
with regard to interactive coding.

The main Max patch in the system (hosting the engine) incudes a facility for receiving
OSC messages over the local network, piping those message into the Scheme interpreter.
In conjuction with some Vim script macros and a small Python utility that receives
text from STDIN and sends it out over TCP, this allows me to arbitrarily send
Scheme code from a Vim window into the engine. The result is that I can
redefine functions from my text editor while the sequencer plays, examine data in the Max console,
and even dump and load text files into the interpreter. This is used
for a number of features:

* Saving sequence data is achieved through serializing the state hashtable
  in a sequencer and writing to disk. This can be loaded directly into the 
  engine, or loaded in a readable form in a text editor and then loaded in the engine.
  This provides a highly flexible loading and saving system. It is trivial
  to save only parts of a project, or to reuse data from one part or project in another.
* High-level arranging can be done in text files which consist of scores
  of function calls. Because these can trigger any function, this can include
  mix automation, or anything possible with the Live API, and these
  can be triggered manually while building the score.
* A Live session itself, and even the operation of the entire platform, can
  be controlled from a text editor with short-cuts. Hotkey macros can be made for really 
  any operation one might want. I have some that reload the interpreter, 
  stop and start playback, or reset various states.
* One can trivially move data from the sequencing engine into text buffers,
  operate on it there (with whatever programmatic utilities are desired),
  and move it back into the engine. This could be extended to sophisticated
  side-car devices that injest sequences, alter them, and when done, resend
  them to the main engine.

Design Conclusion
------------------
Overall, while it is still a work in progress, I have found the environment
enormously productive and satisfying to work with. It is certainly possible
to tax it too far, but I am able to run full ensembles of a dozen sequencers
with a latency of 256 samples, and this is without significant work in optimization.
One of the positive features of s7 Scheme is how easy it is to add new Scheme
functions with C implementations, thus an area of exploration is to see what
can be done that way - parts of the engine that the user is amenable to having locked down 
could be implemented in C, and it should be simple to allow moving back and 
forth between those and Scheme implementations.







